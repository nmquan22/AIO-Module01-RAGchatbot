# ü§ñ RAG Chatbot - H·ªèi ƒê√°p Ti·∫øng Vi·ªát D·ª±a Tr√™n T√†i Li·ªáu Ng∆∞·ªùi D√πng

·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng ki·∫øn tr√∫c RAG (Retrieval-Augmented Generation) ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi ti·∫øng Vi·ªát d·ª±a tr√™n t√†i li·ªáu ng∆∞·ªùi d√πng t·∫£i l√™n. S·ª≠ d·ª•ng m√¥ h√¨nh LLM v√† h·ªá th·ªëng vector Qdrant cho vi·ªác t√¨m ki·∫øm ng·ªØ nghƒ©a.


---

## üèó Ki·∫øn tr√∫c h·ªá th·ªëng

- **Frontend**: ReactJS
- **Backend**: FastAPI
- **Vector Store**: Qdrant
- **Embedding model**: `bkai-foundation-models/vietnamese-bi-encoder`
- **LLM model**: `AITeamVN/Vi-Qwen2-1.5B-RAG-GGUF`
- **Chunking**: Semantic chunking (chia theo nghƒ©a)

---

## üöÄ H∆∞·ªõng d·∫´n tri·ªÉn khai

### 1. Kh·ªüi ch·∫°y Qdrant

```bash
docker run -p 6333:6333 qdrant/qdrant
```

Truy c·∫≠p dashboard: http://localhost:6333/dashboard

---

### 2. Ch·∫°y Backend

```bash
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload
```

| Endpoint  | Ch·ª©c nƒÉng |
|-----------|-----------|
| `/upload` | Upload v√† l∆∞u t√†i li·ªáu (chunked) v√†o vectorstore |
| `/query`  | Truy v·∫•n top 5 ƒëo·∫°n g·∫ßn nh·∫•t |
| `/ask`    | Nh·∫≠n c√¢u h·ªèi, tr·∫£ l·ªùi t·ª´ LLM k√®m ƒëo·∫°n d·∫´n ch·ª©ng |

---

### 3. Frontend

```bash
cd frontend
npm install
npm run dev
```

Truy c·∫≠p t·∫°i: http://localhost:5173

---

## üîç C√°c th√†nh ph·∫ßn backend

### vectorstore.py
- X·ª≠ l√Ω semantic chunking
- L∆∞u vector v√†o Qdrant
- Truy v·∫•n top K ƒëo·∫°n li√™n quan

### llm_pipeline.py
- Load m√¥ h√¨nh GGUF (quantized)
- Ch·∫°y b·∫±ng CPU v·ªõi `llama-cpp-python`

### rag_chain.py
- T·∫°o pipeline `retriever ‚Üí prompt ‚Üí LLM ‚Üí parser`

### llm_logic.py
- H√†m `generate_answer(user_id, query)` tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi v√† d·∫´n ch·ª©ng

---

## üìâ Quantization cho LLMs ‚Äì T·ªëi ∆∞u h√≥a hi·ªáu nƒÉng

### V·∫•n ƒë·ªÅ:
- C√°c LLM l·ªõn nh∆∞ LLaMA 7B, 13B kh√¥ng th·ªÉ ch·∫°y tr√™n CPU
- C·∫ßn gi·∫£m k√≠ch th∆∞·ªõc m√¥ h√¨nh m√† v·∫´n gi·ªØ ƒë·ªô ch√≠nh x√°c

### Gi·∫£i ph√°p:
**Quantization** + **GGUF format**

| Tr·∫°ng th√°i m√¥ h√¨nh | Dung l∆∞·ª£ng |
|--------------------|------------|
| Float32            | 6‚Äì12 GB    |
| Int8               | ~3 GB      |
| Int4 (GGUF)        | ~1.5‚Äì2.5 GB ‚úÖ |

> S·ª≠ d·ª•ng m√¥ h√¨nh `Vi-Qwen2-1.5B-RAG-GGUF` t·ª´ HuggingFace:
> https://huggingface.co/tensorblock/Vi-Qwen2-1.5B-RAG-GGUF

### T√≠ch h·ª£p trong Python:

```python
from llama_cpp import Llama

llm = LlamaCpp(
    model_path=os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "models", "Vi-Qwen2-1.5B-RAG-Q4_K_M.gguf")),
    temperature=0.2,
    top_p=0.95,
    max_tokens=256,
    n_ctx=2048,
    verbose=True
)
```

---

## üìä So s√°nh Vectorstore

| Ti√™u ch√≠        | Qdrant | FAISS | Chroma |
|----------------|--------|-------|--------|
| Tri·ªÉn khai      | ‚úÖ Docker d·ªÖ | ‚ùå C·∫ßn custom code | ‚ö†Ô∏è Ch·ªâ d√πng demo |
| Metadata Filter | ‚úÖ C√≥ | ‚ùå Kh√¥ng | ‚ö†Ô∏è C√≥ nh∆∞ng h·∫°n ch·∫ø |
| Persistent      | ‚úÖ C√≥ | ‚ùå RAM-only | ‚ö†Ô∏è C√≥ nh∆∞ng y·∫øu |
| LangChain       | ‚úÖ T√≠ch h·ª£p s·∫µn | ‚ùå Ph·∫£i t·ª± l√†m | ‚ö†Ô∏è C√≥ nh∆∞ng ch∆∞a t·ªëi ∆∞u |

---
## Demo 

---

### M√†n h√¨nh ƒëƒÉng k√≠ t√†i kho·∫£n  
![Register UI](images/login.png)
### M√†n h√¨nh ch√≠nh  
![Main UI](images/dashboard.png)
### Docker ch·∫°y Qdrant 
![docker UI](images/docker.png)
### Dashboard Qdrant  
![qdrant UI](images/qdrant.png)
### Upload t√†i li·ªáu  
![upload UI](images/upload.png)
![final upload UI](images/finalup.png)
### Query 
![query UI](images/query.png)
### k·∫øt qu·∫£ 
![Result UI](images/answer.png)
![Retriever UI](images/retrive.png)

--- 

## üìé Tham kh·∫£o

- HuggingFace Vi-Qwen2: [https://huggingface.co/tensorblock/Vi-Qwen2-1.5B-RAG-GGUF](https://huggingface.co/tensorblock/Vi-Qwen2-1.5B-RAG-GGUF)
- Qdrant: [https://qdrant.tech](https://qdrant.tech)
- LangChain: [https://docs.langchain.com](https://docs.langchain.com)
